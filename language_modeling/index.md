# Question answering

## Pre-trained models 

| Name | License | Size |  Date | Training data | Metadata | 
| -- | -- | -- | -- | -- | -- |
| [AraBERT](https://arxiv.org/abs/2003.00104) @ [GitHub](https://github.com/aub-mind/arabert) | [License](https://github.com/aub-mind/arabert/blob/master/LICENSE), commercial use ‚úîÔ∏è | BERT-Base architechture  | Feb 2020  | ~70M sentences or ~23GB (MSA) | [Segmenter](http://alt.qcri.org/farasa/segmenter.html) |
| [Arabic-BERT](https://github.com/alisafaya/Arabic-BERT) | [MIT](https://github.com/alisafaya/Arabic-BERT/blob/master/LICENSE) | BERT-BASE | Mar 2020 | ~8.2 Billion words ~95GB| | 
| [hULMonA](https://www.aclweb.org/anthology/W19-4608/) @ [GitHub](https://github.com/aub-mind/hULMonA) | undefined | ULMFiT architecture| Aug 2019 |600,559 Wikipedia articles ~108M words |  |


*More resources coming soon stay tuned ! ü§© You are welcome to contribute to this project ! üôè*

